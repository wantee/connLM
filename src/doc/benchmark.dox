//
// The MIT License (MIT)
//
// Copyright (c) 2017 Wang Jian
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in all
// copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
// SOFTWARE.

/**
  @page benchmark Benchmark of the connLM toolkit

  @section env Experiment Environment

  All experiments are run on the <a href=https://aws.amazon.com/ec2/instance-types/#compute-optimized> AWS c4.4xlarge instance </a>, which has 16 vCPU @ 2.90GHz.

  The binaries are compiled by gcc 4.8.3 with
  <a href=https://software.intel.com/en-us/intel-mkl> Intel MKL </a> as the
  BLAS libary. Thanks to Intel, The MKL license is <a href=https://software.intel.com//qualify-for-free-software/opensourcecontributor> at no cost for open source projects</a>.

  All Detail Results can be found in @c egs/corpus-name/RESULTS.txt

  @section ppl Perplexity

  This table summarizes the performance of some example scripts in terms of PPL.

<table>
<tr>
  <th>Corpus</th>
  <th>\#Words</th>
  <th>Vocab Size</th>
  <th>Model</th>
  <th>Parameters</th>
  <th>Training Time/Speed</th>
  <th>Test Set Perplexity</th>
</tr>
<tr>
  <!-- Corpus               --> <td>SWBD1</td>
  <!-- Words                --> <td></td>
  <!-- Vocab Size           --> <td></td>
  <!-- Model                --> <td>RNN+MaxEnt</td>
  <!-- Parameters           --> <td>200+4/128M</td>
  <!-- Time/Speed           --> <td>-/400k</td>
  <!-- PPL                  --> <td>76</td>
</tr>
<tr>
  <!-- Corpus               --> <td>PTB</td>
  <!-- Words                --> <td></td>
  <!-- Vocab Size           --> <td></td>
  <!-- Model                --> <td>RNN+MaxEnt</td>
  <!-- Parameters           --> <td>200+4/128M</td>
  <!-- Time/Speed           --> <td>-/340k</td>
  <!-- PPL                  --> <td>132</td>
</tr>
<tr>
  <!-- Corpus               --> <td>Tedlium</td>
  <!-- Words                --> <td>266M</td>
  <!-- Vocab Size           --> <td>152k</td>
  <!-- Model                --> <td>RNN+MaxEnt</td>
  <!-- Parameters           --> <td>400+4/2G</td>
  <!-- Time/Speed           --> <td>14hrs/47k</td>
  <!-- PPL                  --> <td>127</td>
</tr>
<tr>
  <!-- Corpus               --> <td>LibriSpeech</td>
  <!-- Words                --> <td>844M</td>
  <!-- Vocab Size           --> <td>200k</td>
  <!-- Model                --> <td>RNN+MaxEnt</td>
  <!-- Parameters           --> <td>300+4/2G</td>
  <!-- Time/Speed           --> <td></td>
  <!-- PPL                  --> <td></td>
</tr>
<tr>
  <!-- Corpus               --> <td>1-Billion</td>
  <!-- Words                --> <td></td>
  <!-- Vocab Size           --> <td>1M</td>
  <!-- Model                --> <td>RNN+MaxEnt</td>
  <!-- Parameters           --> <td></td>
  <!-- Time/Speed           --> <td></td>
  <!-- PPL                  --> <td></td>
</tr>
</table>

  The unit of speed is words/sec.

  @subsection fst_converter FST Perplexity
  This section show the perplexities of converted FST from connLM model.
  The PPLs are computed by the <a href=https://github.com/wantee/fstLM> fstLM </a>
  tool, which are probably better than the PPL of ARPA LM converted from the
  same FST LM.

<table>
<tr>
  <th>Corpus</th>
  <th>Model</th>
  <th>Order</th>
  <th>\#Grams</th>
  <th>Test Set Perplexity</th>
</tr>
<tr>
  <!-- Corpus               --> <td>SWBD1</td>
  <!-- Model                --> <td>RNN+MaxEnt</td>
  <!-- Order                --> <td>4</td>
  <!-- Grams                --> <td></td>
  <!-- PPL                  --> <td></td>
</tr>
<tr>
  <!-- Corpus               --> <td>PTB</td>
  <!-- Model                --> <td>RNN+MaxEnt</td>
  <!-- Order                --> <td>4</td>
  <!-- Grams                --> <td></td>
  <!-- PPL                  --> <td></td>
</tr>
<tr>
  <!-- Corpus               --> <td>Tedlium</td>
  <!-- Model                --> <td>RNN+MaxEnt</td>
  <!-- Order                --> <td>4</td>
  <!-- Grams                --> <td>50M</td>
  <!-- PPL                  --> <td>149</td>
</tr>
<tr>
  <!-- Corpus               --> <td>LibriSpeech</td>
  <!-- Model                --> <td>RNN+MaxEnt</td>
  <!-- Order                --> <td>4</td>
  <!-- Grams                --> <td></td>
  <!-- PPL                  --> <td></td>
</tr>
<tr>
  <!-- Corpus               --> <td>1-Billion</td>
  <!-- Model                --> <td>RNN+MaxEnt</td>
  <!-- Order                --> <td>4</td>
  <!-- Grams                --> <td></td>
  <!-- PPL                  --> <td></td>
</tr>
</table>

  @section wer WER for ASR

  This section shows some results of connLM rescore for ASR. The experiments
  are done with <a href=http://kaldi-asr.org/> Kaldi </a> Toolkit.

  @subsection ted Tedlium Release 2
@verbatim
%WER 9.9 | 507 17783 | 91.4 6.0 2.6 1.3 9.9 79.1 | 0.028 | exp/chain/tdnn1b_sp_bi/decode_dev/score_8_0.0/ctm.filt.filt.sys
%WER 8.2 | 507 17783 | 93.1 4.8 2.1 1.3 8.2 73.2 | -0.815 | exp/chain/tdnn1b_sp_bi/decode_dev_connlm_L0.75/score_7_0.0/ctm.filt.filt.sys

%WER 9.8 | 1155 27500 | 91.5 5.9 2.7 1.3 9.8 74.4 | 0.067 | exp/chain/tdnn1b_sp_bi/decode_test/score_8_0.0/ctm.filt.filt.sys
%WER 8.1 | 1155 27500 | 93.0 4.5 2.5 1.1 8.1 66.8 | -0.424 | exp/chain/tdnn1b_sp_bi/decode_test_connlm_L0.75/score_8_0.0/ctm.filt.filt.sys
@endverbatim

*/
