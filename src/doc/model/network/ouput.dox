//
// The MIT License (MIT)
//
// Copyright (c) 2016 Wang Jian
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in all
// copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
// SOFTWARE.

/**
  @page model_network_output The Output Layer

  @section model_network_output_intro Introduction

  A connLM model can only contain one output layer, which is shared by
  one or more component models.

  An output layer must be generated before other components added.

  The related source code is in output.h. output_generate() can be called
  to generate a output layer with specific options.

  The command line interface for generating output layer is
  @ref cmd_output "connlm-output".

  @section model_network_output_process The Building Process

  Output layer is a tree whose structure is based on counts of words in
  vocabulary. The main goal is to make the frequent words with less
  computations during the softmax summation, and the rare words with more
  computations. Thus, the total computational complexity could be lower.

  The output_opt_t can be used to control the building process of tree:

  @code {.c}
  typedef struct _output_opt_t_ {
      output_method_t method; /**< constructing method. */
      int max_depth; /**< maximum depth of tree. */
      int max_branch; /**< maximum number of branches. */
  } output_opt_t;
  @endcode

  @c method specifies which method to be applied to build the tree.
  @c max_depth controls the maximum depth of tree, while @c max_branch
  determines maximum number of branches for every internal node in the tree.

  There are two methods to build the tree, the Top-Down and the Bottom-Up. They
  are different for the direction of tree building. Both will result a tree
  with all words on leaf nodes.

  For the Top-Down method, we first put all words in the root node of tree.
  Then, the words within a node is split to @c max_branch subset, with the
  total counts of every subset is roughly equal with each other. The subsets
  are then became a node and added to the tree. The splitting process keeps
  running until every leaf node of the tree contains only one word, or the
  @c max_depth is met.

  For the Bottom-Up method, in contrast, we will perform a merging process
  similar with the algorithm to build a Huffman tree. All words, initially,
  are placed on a leaf node of the tree. Then, we select
  the @c max_branch nodes with largest count, and merge them as a new node. At
  last, they will be merged to a single root node, or when we reach the
  @c max_depth, we stop the merging and place a root node to connect all
  remaining nodes.

  Following are example of trees built by both methods from a small vocabulary.

  @dotfile output_topdown.dot "Simple output tree built from top-down"

  @dotfile output_bottomup.dot "Simple output tree built from bottom-up"

  @section model_network_output_norm The Normalization Method

  Besides the structure, the other property for output layer is the
  normalization method. This could be specified in the topology file together
  with configuration of @ref model_network_comp_topo "other  components".
  The normalization is performed on all children for every internal node.

  The format for output normalization method in topology file is:

  @code
  <output>
    property norm=softmax
  </output>
  @endcode

  Currently, connLM only support the Softmax normalization. We may include some
  sampling based normalization, e.g., NCE.

  Since there would be more nodes in tree than words, in order to save space
  and computation, we do not implement the softmax in the usual way. Recall
  that the formula for softmax is

  @f[
    \Pr(Y = i) = \frac{e^{x_i}}{\sum_{k=1}^{K}{e^{x_k}}}
  @f]

  However, we also can see it as multinomial logit, by fixing the score of
  Kth class to 1, i.e.,

  @f[
    \begin{aligned}
    \Pr(Y = K) &= \frac{1}{1+\sum_{k=1}^{K-1}{e^{x_k}}} \\
    \Pr(Y = i) &= \frac{e^{x_i}}{1+\sum_{k=1}^{K-1}{e^{x_k}}}, \forall i < K
    \end{aligned}
  @f]

  In this way, for every internal nodes in the tree, we can save one vector
  for both storage and computation. For a perfect binary tree with N leafs,
  there will be (N - 1) non-leaf nodes. With the regular softmax, we will need
  (2N - 2) vectors as weight, however, by applying the multi-logit, the demand
  can be reduced by (N - 1), which is the half of the original.
*/
